import cv2
import HandTrackingModule as htm
import numpy as np
import mediapipe as mp
import time
import pynput
from pynput.keyboard import Key, Controller
import mouse

keyboard = Controller()
cap = cv2.VideoCapture(0)

lmlist = []
handX, handY = 0, 0

detector = htm.handDetector(detectionCon=0.5)

while True:
    success, img = cap.read()
    img = cv2.flip(img, +1)
    img = detector.findHands(img)
    lmList = detector.findPosition(img, draw=False)
    if lmList:
        #
        # keypresses

        #index
        if lmList[8][2] > lmList[6][2]:
            keyboard.press('d')
            if lmList[8][2] < lmList[6][2]:
                keyboard.release('a')
        #middle
        if lmList[12][2] > lmList[10][2]:
            keyboard.press('w')
            if lmList[12][2] < lmList[10][2]:
                keyboard.release('w')

        #ring
        if lmList[16][2] > lmList[14][2]:
            keyboard.press('a')
            if lmList[16][2] < lmList[14][2]:
                keyboard.release('a')
        #thumb
        if lmList[4][1] < lmList[1][1]:
            keyboard.press(Key.space)
            if lmList[4][1] > lmList[1][1]:
                keyboard.release(Key.space)
        #pinky
        if lmList[20][2] > lmList[18][2]:
            keyboard.press('e')
            if lmList[20][2] < lmList[18][2]:
                keyboard.release('e')




        # mouse movement

        # handX = np.interp(lmList[16][1], (150, 550), (0, 1535))
        # handY = np.interp(lmList[16][2], (20, 240), (0, 863))
        # mouseIN.move(handX - mouseIN.position[0], handY - mouseIN.position[1])


    # for default camera
    # 130-580 - x
    # 30 - 270 - y
    # for external
    # x - 150,550
    # y - 15,240
    # screen res = 1535, 863

    cv2.imshow("image", img)
    cv2.waitKey(1)


